{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Lab 3: Building AI Systems"
      ],
      "metadata": {
        "id": "qIOnMSlQcjSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teaching Students to Build AI Systems (Making LLM calls)"
      ],
      "metadata": {
        "id": "UMsdfLnXhiIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation"
      ],
      "metadata": {
        "id": "quRua816celk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q smartfunc\n"
      ],
      "metadata": {
        "id": "_tZoii-ocpNc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Variables"
      ],
      "metadata": {
        "id": "GQZDoUbBegRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set environment variable\n",
        "os.environ['OPENAI_API_KEY'] = '' #Enter API Key Here\n"
      ],
      "metadata": {
        "id": "CbGweciDej28"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Calls\n",
        "\n",
        "- **Import statement**:  \n",
        "  `from smartfunc import backend`  \n",
        "  - Imports the `backend` decorator from the `smartfunc` module.\n",
        "\n",
        "- **Function declaration**:  \n",
        "  `@backend(\"gpt-4o\")`  \n",
        "  - Decorates the `generate_summary` function to indicate that it should be executed using the GPT-4o backend, likely delegating execution to an AI model.\n",
        "\n",
        "- **Function definition**:  \n",
        "  `def generate_summary(text: str):`  \n",
        "  - Defines a function named `generate_summary` that takes a single string argument `text`.\n",
        "\n",
        "- **Docstring prompt template**:  \n",
        "  `\"\"\"Generate a summary of the following text: {{ text }}\"\"\"`  \n",
        "  - Provides a prompt template using double curly braces (`{{ text }}`) for inserting the input text dynamically when calling the backend model.\n",
        "\n",
        "- **Function body**:  \n",
        "  `pass`  \n",
        "  - The function body is empty; the logic is presumably handled by the `@backend` decorator and the docstring prompt.\n",
        "\n",
        "- **Function call**:  \n",
        "  `generate_summary(\"Django ORM\")`  \n",
        "  - Calls the function with the input `\"Django ORM\"`, triggering the GPT-4o backend to generate a summary of that topic."
      ],
      "metadata": {
        "id": "vk5IS0c5ct-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smartfunc import backend\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "@backend(\"gpt-4o\")\n",
        "def generate_answer(text: str):\n",
        "    \"\"\"\n",
        "        You are friendly buddy bot. Explain in detail for school student.\n",
        "        Use lots of emoji's and reply in Markdown\n",
        "        Answer this question: {{ text }}\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "Markdown(generate_answer(\"Why is the sky blue?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "F68rnibwODqm",
        "outputId": "0cc18c48-7a89-4315-d5d6-25c2188e8e49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Hey there! ğŸŒŸ I'm super excited to explain why the sky is blue. This is a really cool question and it's all about the science of light. Let's dive in! ğŸŒˆ\n\n### Why is the Sky Blue? ğŸŒŒ\n\n1. **Light from the Sun** â˜€ï¸:\n    - The light we get from the sun looks white, but it's actually made up of all the colors of the rainbow mixed together! ğŸŒˆ\n    - When that white light passes through a prism (or in this case, Earth's atmosphere), it separates into different colors.\n\n2. **Earth's Atmosphere** ğŸŒ:\n    - The atmosphere is full of tiny particles and gasesâ€”like nitrogen and oxygen.\n    - When sunlight reaches Earth, it bumps into these particles in the atmosphere.\n\n3. **Scattering of Light** ğŸŒ¬ï¸:\n    - Not all colors of light are scattered equally. Blue light waves are shorter and smaller, so they get scattered much more than other colors like red, which have longer waves.\n    - This scattering is called **Rayleigh scattering**! ğŸ¤“\n\n4. **Why Blue?** ğŸ”µ:\n    - Because blue light is scattered everywhere, in every direction, when you look up, the sky appears blue to our eyes. ğŸ‘€\n    - If Earth had no atmosphere, the sky would look dark because there would be nothing to scatter the sunlight!\n\n5. **Sunset and Sunrise** ğŸŒ…:\n    - During sunset and sunrise, the sky can appear red, orange, and pink because the sun is lower in the sky. This means sunlight has to travel through more of the atmosphere, scattering away the blue light and letting the reds and oranges through.\n\nSo, the next time you look up at the big, blue sky, remember it's all about the light being playful. ğŸŒˆ Isn't science amazing? If you have more questions, just let me know! ğŸ˜Š\n\n--- \n\nAnd there you go! Hope that helps you understand why our sky is such a beautiful blue most of the time. Keep looking up and wondering! ğŸŒŸ"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from smartfunc import backend\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "\n",
        "@backend(\"gpt-4o\")\n",
        "def draw_ascii(text: str):\n",
        "    \"\"\"\n",
        "        You draw amazing ASCII diagrams\n",
        "        Draw this in ASCII: {{ text }}\n",
        "        Only return ASCII.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "ascii_pic = draw_ascii(\"Side view of a Car\")\n",
        "print(ascii_pic)"
      ],
      "metadata": {
        "id": "kFx00Ar1Pq4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108e9518-9663-453c-a9a8-04a6435300b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```\n",
            "      ______\n",
            "     //  ||\\ \\\n",
            "   _//___||_\\ \\___\n",
            "  )  _          _  \\\n",
            "  |_/ \\________/ \\_|\n",
            "___\\_/__________\\_/____\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from smartfunc import backend\n",
        "\n",
        "@backend(\"gpt-4o\")\n",
        "def generate_summary(text: str):\n",
        "    \"\"\"Generate a summary of the following text: {{ text }}. Reply using Markdown.\"\"\"\n",
        "    pass\n",
        "\n",
        "Markdown(generate_summary(\"Photosynthesis\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "ZYtl38RmdEbj",
        "outputId": "5d2defe1-a903-4ae5-af56-d5a2f03099e5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Photosynthesis is the process used by plants, algae, and some bacteria to convert light energy into chemical energy stored in glucose. This process occurs mainly in the chloroplasts of plant cells. Photosynthesis involves two main stages: the light-dependent reactions and the light-independent reactions (Calvin cycle). In the first stage, light energy is captured by chlorophyll and used to split water molecules, releasing oxygen and generating ATP and NADPH. In the Calvin cycle, ATP and NADPH fuel the conversion of carbon dioxide into glucose. Photosynthesis is vital for life on Earth as it provides the oxygen we breathe and the food we consume."
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from smartfunc import backend\n",
        "\n",
        "@backend(\"gpt-4o\")\n",
        "def generate_joke(text: str):\n",
        "    \"\"\"Generate a funny joke about: {{ text }}\"\"\"\n",
        "    pass\n",
        "\n",
        "generate_joke(\"Calculus\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oeEfksfAf3JY",
        "outputId": "7c19deb0-60ec-4872-f3df-cbe0eeada88f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why was the calculus book so unhappy? \\n\\nBecause it had too many problems to differentiate!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teaching Students to Build A Chatbot"
      ],
      "metadata": {
        "id": "13sMP5Xrik5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain openai langchain-openai"
      ],
      "metadata": {
        "id": "FNG4ynxoRmau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a02ee76-777b-4832-9410-f2217e6a1282"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/62.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.3/1.2 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "id": "E3O9L8cWipqR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set environment variable\n",
        "os.environ['OPENAI_API_KEY'] = '' #Enter API Key Here"
      ],
      "metadata": {
        "id": "TXaIyQqtiqct"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple LLM Call"
      ],
      "metadata": {
        "id": "hfTg8nsoixvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.9, model=\"gpt-4o\")\n",
        "\n",
        "text = \"Tell me about the QLD State of Origin? Only return Markdown, don't include text saying you have included markdown.\"\n",
        "llm_response = llm.invoke(text)\n",
        "\n",
        "display(Markdown(llm_response.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "c-Ny0SRei0D4",
        "outputId": "1480bda4-848e-40a3-f742-14c5d0a9ddea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Queensland State of Origin\n\n## Overview\nThe Queensland State of Origin team, commonly referred to as the \"Maroons,\" represents Queensland in the annual State of Origin series against New South Wales. This rugby league series is one of Australia's most significant sporting events, showcasing the intense rivalry between the two states.\n\n## History\n- **Inception**: The State of Origin concept was introduced in 1980, allowing players to represent the state they were first selected to play senior representative rugby league, regardless of where they currently play. This replaced the previous system where players represented the state they played in.\n- **Queensland's Influence**: Known for their passionate approach and \"never say die\" attitude, Queensland has been a formidable force in the series, boasting numerous victories.\n\n## Achievements\n- **Series Wins**: Queensland has won many series over the decades, notably dominating the 2006-2013 period with an eight-year winning streak, a testament to their resilience and skill.\n- **Legendary Players**: The team has featured numerous iconic players such as Wally Lewis, Darren Lockyer, Allan Langer, and Cameron Smith, who have left lasting legacies in the sport.\n\n## Key Features\n- **Jersey**: The team's traditional jersey color is maroon, hence the nickname \"Maroons.\"\n- **Home Ground**: Suncorp Stadium in Brisbane is considered the spiritual home for Queenslandâ€™s State of Origin games, known for its electric atmosphere.\n\n## Culture and Impact\n- **Passion**: The State of Origin is deeply ingrained in Queensland culture, with the series often compared to grand finals in terms of importance.\n- **Community Engagement**: The Maroons have always been heavily supported throughout the state, with fan engagement activities and events occurring annually around the series.\n\n## Recent Developments\n- **Coaching and Staffing**: Changes in coaching and support staff frequently occur as the team adapts strategies to maintain competitive performance.\n- **Rising Stars**: New talent continually emerges, ensuring the Maroons remain competitive against their southern rivals.\n\nThe Queensland State of Origin team remains an iconic symbol of Queensland's sporting culture, continually striving for excellence and representing the pride of the state on the rugby league field."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Chatbot with UI"
      ],
      "metadata": {
        "id": "pkHpHyz0i1AW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgHRYrTfi3VZ",
        "outputId": "34345543-3f0d-4425-e136-009b1329eda2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With system prompt\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "import gradio as gr\n",
        "\n",
        "# Initialize the language model with your desired settings\n",
        "llm = ChatOpenAI(temperature=0.8, model='gpt-4o')\n",
        "\n",
        "# Define a system prompt\n",
        "system_prompt = \"You are an HTML tutor. You only answer questions about HTML Web programming and nothing else.\"\n",
        "\n",
        "def chat(message, history):\n",
        "    # Convert the history into LangChain format and prepend the system prompt to the latest message\n",
        "    chat_history = []\n",
        "    for human, ai in history:\n",
        "        chat_history.append(HumanMessage(content=human))\n",
        "        chat_history.append(AIMessage(content=ai))\n",
        "\n",
        "    # Add the system prompt to the latest user message\n",
        "    modified_message = system_prompt + message\n",
        "    chat_history.append(HumanMessage(content=modified_message))\n",
        "\n",
        "    # Get the response from the language model\n",
        "    response = llm(chat_history)\n",
        "    return response.content\n",
        "\n",
        "# Launch the Gradio chat interface\n",
        "gr.ChatInterface(chat).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "faJwmzn7i8oJ",
        "outputId": "65afaa99-a8bc-42e0-f0ad-3edbc6835ad9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:338: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2d17eb58355ee0beee.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2d17eb58355ee0beee.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}